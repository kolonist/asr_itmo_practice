{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e5b3f1c-f656-4b44-9385-7bfcd1558469",
   "metadata": {},
   "source": [
    "# Лабораторная работа 1. Подсчет ошибки распознавания"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5c72b7-e242-412c-851c-02479bff8773",
   "metadata": {},
   "source": [
    "WER (Word Error Rate) является метрикой для оценки качества систем распознавания речи. Она показывает процент ошибочных слов в гипотезе распознавания по сравнению с эталонным текстом. WER учитывает три типа ошибок: вставки, удаления и замены. \n",
    "$$ WER = {I + D + S \\over D + S + C} $$\n",
    "где I, D, S - количество втавок, удалений и замен, соответственно. C - количество правильно распознанных слов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa45f820-960d-47bd-bd7d-9bd284a239d7",
   "metadata": {},
   "source": [
    "Лабораторная работа состоит из трех частей. Первая часть (функция подсчета WER) обязательная, остальные дополнительные. Всего за работу можно получить максимум 20 баллов. 4 за сдачу в срок и 16 за задания: \n",
    "* функция подсчета WER (тест 1.a, 1.b) - 8 баллов\n",
    "* функция подсчета WER и ошибки пунктуации (тест 2.a) - 4 балла\n",
    "* функция подсчета SA-WER (тест 3.а) - 4 балла"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca5fa23",
   "metadata": {},
   "source": [
    "# Общая секция &mdash; импорты, инициализация, константы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88b0bb01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11be20b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# знаки пунктуации\n",
    "RE_PUNCTUATIONS = re.compile(r\"(?u)([\\.!?,;:\\-\\(\\)\\\"'`«»$%*/\\|+~\\^&#\\{\\}\\[\\]=<>\\\\]+)\")\n",
    "\n",
    "# пробельные символы\n",
    "RE_WHITESPACE = re.compile(r\"\\s+\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7765f57-93d1-4310-b2c6-b88189c16099",
   "metadata": {},
   "source": [
    "# 1. Word Error Rate (8 баллов)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af47bb7-3c52-4d0f-aa72-426bad9089fc",
   "metadata": {},
   "source": [
    "## 1.a. подсчет WER \n",
    "\n",
    "\n",
    "Функция должна принимать две строки в качестве входных данных: эталонный текст и распознанный текст. Эталонный текст - это то, что произносится в аудиозаписи, а гипотеза распознавания - это текст, полученный от системы распознавания речи. Для корректного вычисления ошибки распознавания необходимо удалить все символы пунктуации и привести все слова к нижнему регистру.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56c63b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(src:str, original_case:bool=False) -> list[str]:\n",
    "    \"\"\"Удаление знаков пунктуации и приведение к нижнему регистру.\"\"\"\n",
    "    result = re.sub(RE_PUNCTUATIONS, \"\", src)\n",
    "\n",
    "    if not original_case:\n",
    "        result = result.lower()\n",
    "\n",
    "    result = re.split(RE_WHITESPACE, result)\n",
    "    result = [ word.strip() for word in result if word.strip() != \"\" ]\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06e89202-5b26-4a55-b3a0-2e1996d07552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Error Rate: 33.33%\n"
     ]
    }
   ],
   "source": [
    "def creade_distance_matrix(reference_text:str, recognized_text:str) -> list[list[int]]:\n",
    "    \"\"\"Построение матрицы расстояний.\"\"\"\n",
    "\n",
    "    # Приведение текста к нижнему регистру, удаление символов пунктуации и разбивка на слова\n",
    "    reference_words = preprocess_text(reference_text)\n",
    "    recognized_words = preprocess_text(recognized_text)\n",
    "\n",
    "    # Инициализация матрицы для подсчета расстояния между словами\n",
    "    distance_matrix = [[0] * (len(recognized_words) + 1) for _ in range(len(reference_words) + 1)]\n",
    "    \n",
    "    # Наполнение первой строки матрицы\n",
    "    for i in range(len(reference_words) + 1):\n",
    "        distance_matrix[i][0] = i\n",
    "\n",
    "    # Наполнение первого столбца матрицы\n",
    "    for j in range(len(recognized_words) + 1):\n",
    "        distance_matrix[0][j] = j\n",
    "\n",
    "    def cost(i:int, j:int) -> int:\n",
    "        return 0 if reference_words[i-1] == recognized_words[j-1] else 1\n",
    "\n",
    "    # Заполнение матрицы расстояний методом динамического программирования\n",
    "    for i in range(1, len(reference_words) + 1):\n",
    "        for j in range(1, len(recognized_words) + 1):\n",
    "            distance_matrix[i][j] = min([\n",
    "                distance_matrix[i][j-1] + 1,\n",
    "                distance_matrix[i-1][j] + 1,\n",
    "                distance_matrix[i-1][j-1] + cost(i, j),\n",
    "            ])\n",
    "\n",
    "    return distance_matrix\n",
    "\n",
    "\n",
    "def calculate_wer(reference_text: str, recognized_text: str) -> float:\n",
    "    \"\"\"Вычисление WER.\"\"\"\n",
    "\n",
    "    # строим матрицу расстояний\n",
    "    distance_matrix = creade_distance_matrix(reference_text, recognized_text)\n",
    "\n",
    "    # расстояние Левенштейна - самый правый нижний элемент\n",
    "    levenstein_distance = distance_matrix[-1][-1]\n",
    "\n",
    "    # Расчет WER  (в процентах)\n",
    "    wer = levenstein_distance / (len(distance_matrix) - 1) * 100\n",
    "\n",
    "    return wer\n",
    "\n",
    "# отладочный запуск\n",
    "wer = calculate_wer('Я ел солонину', 'Я ел слона')\n",
    "print(f\"Word Error Rate: {wer:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f604bfbe-3af2-4550-9119-9031b65a06d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 1.a passed\n"
     ]
    }
   ],
   "source": [
    "def assert_wer(ref, hyp, ideal_wer):\n",
    "    wer = calculate_wer(ref, hyp)\n",
    "    assert round(wer, 2) == round(ideal_wer, 2), f\"for '{hyp=}' and '{ref=}' {ideal_wer=}, calculate_wer {wer=}\"\n",
    "    \n",
    "def test_wer():\n",
    "    assert_wer('привет студент', 'привет студент', 0)\n",
    "    assert_wer('привет! Студент.', 'Привет, студент?', 0)\n",
    "    assert_wer('привет студент', 'студент', 50)\n",
    "    assert_wer('привет студент', '', 100)\n",
    "    assert_wer('привет студент', 'студент привет', 100)\n",
    "    assert_wer('привет', 'привет студент', 100)\n",
    "    assert_wer('привет студент привет как дела', 'студент привет', 60)\n",
    "    assert_wer('привет студент привет как дела', 'привет как дела', 40)\n",
    "    assert_wer('привет студент привет как дела ', 'привет студент дела ', 40)\n",
    "    assert_wer('привет студент привет как дела '*100, 'привет студент дела '*100, 40)\n",
    "\n",
    "    print(f\"Test 1.a passed\")\n",
    "    \n",
    "test_wer() \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b32777-0fae-4999-9843-88313c1e3607",
   "metadata": {},
   "source": [
    "## 1.b. Построение выравнивания\n",
    "Реализованная в части 1.a. функция выдает только суммарное значение ошибки распознавания, не давая понимания, в чем состоят основные проблемы распознавания. \n",
    "\n",
    "Значение WER получается из трех видов ошибок: \n",
    "* вставка (insertion)\n",
    "* удаление (deletion)\n",
    "* замена (substitution)\n",
    "\n",
    "Каждый тип ошибок имеет свое значение и указывает на определенные недостатки системы. Например, большое количество вставок означает, что ASR слышит речь там где ее нет. А большое количество удалений показывает, что целевая речь пропускается и не транскрибируется. \n",
    "\n",
    "Кроме числовых значений каждой ошибки, для анализа результатов работы системы может пригодиться выравнивание эталонной текстовки и гипотезы распознавания относительно друг друга. \n",
    "\n",
    "пример выравнивания: \n",
    "\n",
    "```\n",
    ">>> tabulate(ali)\n",
    "\n",
    "Я сегодня  ***   учуcь  в  универе\n",
    "Я    с    завтра учусь *** универе  \n",
    "C    S      I      C    D    C    \n",
    "```\n",
    "\n",
    "Реализуйте функцию, которая кроме числового значения WER возвращает выравнивание, а также значения каждого типа ошибок распознавания (вставки, удаления, замены)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "414a0cdb-7230-493a-93ba-2d15547a537a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tabulate in /home/raccoon/.local/lib/python3.11/site-packages (0.9.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tabulate\n",
    "from tabulate import tabulate\n",
    "# используйте tabulate для отладки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d6d7687-ff3a-4a46-80ec-12efcab49027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "wer = 66.66666666666666\n",
      "cor = 4\n",
      "del = 1\n",
      "ins = 2\n",
      "sub = 1\n",
      "\n",
      "Результат:\n",
      "\n",
      "Я  ***      ***      сегодня  учусь  в  университете  ИТМО\n",
      "Я   с   завтрашнего    дня    учусь  в      ***       ИТМО\n",
      "C   I        I          S       C    C       D         C\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def calculate_wer_with_alignment(reference_text: str, recognized_text: str):\n",
    "\n",
    "    # Перенесите сюда код из задания 1.a.\n",
    "\n",
    "    # расстояние Левенштейна\n",
    "    distance_matrix = creade_distance_matrix(reference_text, recognized_text)\n",
    "\n",
    "    levenstein_distance = distance_matrix[-1][-1]\n",
    "\n",
    "    wer = levenstein_distance / (len(distance_matrix) - 1) * 100\n",
    "\n",
    "    # разбивка текста на слова и удаление пунктуации\n",
    "    reference_words = preprocess_text(reference_text, original_case=True)\n",
    "    recognized_words = preprocess_text(recognized_text, original_case=True)\n",
    "\n",
    "    # используя distance_matrix восстановите путь (набор операций), который соответстует найденому WER \n",
    "    insertion = 0     # horisontal move\n",
    "    deletion = 0      # vertical move\n",
    "    substitution = 0  # diagonal move\n",
    "    correct = 0\n",
    "    ali = [\n",
    "        [], # reference\n",
    "        [], # recognized\n",
    "        [], # operations\n",
    "    ]\n",
    "\n",
    "    i = len(distance_matrix) - 1\n",
    "    j = len(distance_matrix[0]) - 1\n",
    "    finished = False\n",
    "    while i > 0 or j > 0:\n",
    "        current_value = distance_matrix[i][j]\n",
    "\n",
    "        try_insertion = distance_matrix[i][j-1]\n",
    "        try_deletion = distance_matrix[i-1][j]\n",
    "        try_substitution = distance_matrix[i-1][j-1]\n",
    "\n",
    "        min_value = min([try_insertion, try_deletion, try_substitution])\n",
    "\n",
    "        # ход по диагонали\n",
    "        if try_substitution == min_value and abs(current_value - min_value) <= 1:\n",
    "            if current_value - min_value == 1:\n",
    "                substitution += 1\n",
    "                ali[2].append(\"S\")\n",
    "            else:\n",
    "                correct += 1\n",
    "                ali[2].append(\"C\")\n",
    "\n",
    "            i -= 1\n",
    "            j -= 1\n",
    "\n",
    "            ali[0].append(reference_words[i])\n",
    "            ali[1].append(recognized_words[j])\n",
    "\n",
    "        # ход по горизонтали\n",
    "        elif try_insertion == min_value and abs(current_value - min_value) <= 1:\n",
    "            insertion += 1\n",
    "            j -= 1\n",
    "\n",
    "            ali[2].append(\"I\")\n",
    "            ali[0].append(\"***\")\n",
    "            ali[1].append(recognized_words[j])\n",
    "\n",
    "\n",
    "        # ход по вертикали\n",
    "        else:\n",
    "            deletion += 1\n",
    "            i -= 1\n",
    "\n",
    "            ali[2].append(\"D\")\n",
    "            ali[0].append(reference_words[i])\n",
    "            ali[1].append(\"***\")\n",
    "\n",
    "\n",
    "    # ali[0]=  разбитый по словам референс. Втавки отабражаются в эталонном выравнивании с помощью \"***\"\n",
    "    # ali[1] = разбитая по словам гипотеза.\n",
    "    # ali[2] = аннотация \n",
    "    assert len(ali[0]) == len(ali[1]) == len(ali[2]), f\"wrong ali {ali}\"\n",
    "    \n",
    "    return {\"wer\" : wer,\n",
    "            \"cor\": correct,\n",
    "            \"del\": deletion,\n",
    "            \"ins\": insertion,\n",
    "            \"sub\": substitution,\n",
    "            \"ali\": [ list(reversed(line)) for line in ali ]}\n",
    "\n",
    "\n",
    "# отладочный запуск\n",
    "result = calculate_wer_with_alignment(\n",
    "    \"Я сегодня учусь в университете ИТМО\",\n",
    "    \"Я с завтрашнего дня учусь в ИТМО\"\n",
    ")\n",
    "\n",
    "print(f\"\"\"\n",
    "wer = {result[\"wer\"]}\n",
    "cor = {result[\"cor\"]}\n",
    "del = {result[\"del\"]}\n",
    "ins = {result[\"ins\"]}\n",
    "sub = {result[\"sub\"]}\n",
    "\n",
    "Результат:\n",
    "\n",
    "{tabulate(result[\"ali\"], stralign=\"center\", tablefmt=\"plain\")}\n",
    "\"\"\")\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f0ed11e-8d37-4478-bef2-fe9d41755d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def calculate_wer_with_alignment(reference_text: str, recognized_text: str):\n",
    "#     return {\n",
    "#             \"wer\" : 0,\n",
    "#             \"cor\": 2, \n",
    "#             \"del\": 0,\n",
    "#             \"ins\": 0,\n",
    "#             \"sub\": 0,\n",
    "#             \"ali\": [[\"привет\", \"студент\"],[\"привет\", \"студент\"],['C', 'C']]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ff4fe6c-c548-4f60-bcf9-95a164f43645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 1.b passed\n"
     ]
    }
   ],
   "source": [
    "def assert_wer_with_alignment(ref, hyp, ideal_report):\n",
    "    report = calculate_wer_with_alignment(ref, hyp)\n",
    "    for k, v in ideal_report.items():\n",
    "        if isinstance(v, float):\n",
    "            assert round(v, 2) == round(report[k], 2), f\"for '{hyp=}' and '{ref=}' {ideal_report=}, calculate_wer {report=}\"\n",
    "        else:\n",
    "            assert v == report[k], f\"for '{hyp=}' and '{ref=}' {ideal_report=}, calculate_wer {report=}\"\n",
    "\n",
    "    \n",
    "def test_wer_with_alignment():\n",
    "    assert_wer_with_alignment('привет студент', 'привет студент',  {\n",
    "            \"wer\" : 0,\n",
    "            \"cor\": 2, \n",
    "            \"del\": 0,\n",
    "            \"ins\": 0,\n",
    "            \"sub\": 0,\n",
    "            \"ali\": [[\"привет\", \"студент\"],[\"привет\", \"студент\"],['C', 'C']]})\n",
    "    assert_wer_with_alignment('привет студент', 'студент', {\n",
    "            \"wer\" : 50,\n",
    "            \"cor\": 1, \n",
    "            \"del\": 1,\n",
    "            \"ins\": 0,\n",
    "            \"sub\": 0,\n",
    "            \"ali\": [[\"привет\", \"студент\"],[\"***\", \"студент\"],['D', 'C']]})\n",
    "    assert_wer_with_alignment('привет', 'привет студент', {\n",
    "            \"wer\" : 100,\n",
    "            \"cor\": 1, \n",
    "            \"del\": 0,\n",
    "            \"ins\": 1,\n",
    "            \"sub\": 0,\n",
    "            \"ali\": [[\"привет\", \"***\"],[\"привет\", \"студент\"],['C', 'I']]})\n",
    "    assert_wer_with_alignment('привет студент', 'пока студент',  {\n",
    "            \"wer\" : 50,\n",
    "            \"cor\": 1, \n",
    "            \"del\": 0,\n",
    "            \"ins\": 0,\n",
    "            \"sub\": 1,\n",
    "            \"ali\": [[\"привет\", \"студент\"],[\"пока\", \"студент\"],['S', 'C']]})\n",
    "\n",
    "    print(f\"Test 1.b passed\")\n",
    "    \n",
    "test_wer_with_alignment() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983a8e14-f4f1-4441-a72d-2fa693d72474",
   "metadata": {},
   "source": [
    "# 2. WER с пунктуацией (4 балла)\n",
    "Попробуйте модифицировать WER таким образом, чтобы получившаяся метрика учитавала ошибки расстановки знаков препинания. \n",
    "\n",
    "Для этого надо ввести ограничение в алгоритм подсчета distance_matrix таким образом, чтобы запретить делать замену знака препинания на слово и наоборот.\n",
    "\n",
    "Пример выравнивания \n",
    "```\n",
    "Я сегодня  .   ***   ***  А ты  \n",
    "Я    с    *** завтра  ?   А ты  \n",
    "C    S    D_p   I    I_p  C  C    \n",
    "```\n",
    "Здесь суффикс _p в аннотации к ошибкам означает **ошибки пунктуации**\n",
    "\n",
    "\n",
    "Задание: \n",
    "Напишите функцию, которая кроме стандартного WER считает дополнительно PunctuaionErrorRate (PER) по формуле\n",
    "\n",
    "$$ PER = {I_p + D_p + S_p \\over D_p + S_p + C_p} $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5faccb90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Токенизированная строка: ['Я', 'сегодня', '.', 'А', 'ты', '?']\n",
      "\n",
      "Я -> слово\n",
      "сегодня -> слово\n",
      ". -> знак пунктуации\n",
      "А -> слово\n",
      "ты -> слово\n",
      "? -> знак пунктуации\n",
      "\n",
      "слово1 <> ?      = False\n",
      "слово1 <> слово2 = True\n",
      "!      <> слово2 = False\n",
      "!      <> ?      = True\n"
     ]
    }
   ],
   "source": [
    "def preprocess_text_with_punctuation(src:str, original_case:bool=False) -> list[str]:\n",
    "    \"\"\"Разбиение текста на слова и значи препинания.\"\"\"\n",
    "    result = re.sub(RE_PUNCTUATIONS, r\" \\1 \", src)\n",
    "\n",
    "    if not original_case:\n",
    "        result = result.lower()\n",
    "\n",
    "    result = re.split(RE_WHITESPACE, result)\n",
    "    result = [ word.strip() for word in result if word.strip() != \"\" ]\n",
    "\n",
    "    return result\n",
    "\n",
    "def is_word(str) -> bool:\n",
    "    \"\"\"Проверка, является ли слово словом или знаком препинания.\"\"\"\n",
    "    return not RE_PUNCTUATIONS.match(str)\n",
    "\n",
    "def same(str1, str2):\n",
    "    \"\"\"Возвращает True, или если обе строки являются словами, \n",
    "    или если обе спроки являются знаками препинания.\"\"\"\n",
    "\n",
    "    return not (is_word(str1) ^ is_word(str2))\n",
    "\n",
    "# отладочный запуск\n",
    "str = \"Я сегодня. А ты?\"\n",
    "tokens = preprocess_text_with_punctuation(str, original_case=True)\n",
    "print(\"Токенизированная строка:\", tokens)\n",
    "\n",
    "print()\n",
    "for token in tokens:\n",
    "    print(f\"{token} -> {'слово' if is_word(token) else 'знак пунктуации'}\")\n",
    "\n",
    "print()\n",
    "print(f\"слово1 <> ?      =\", same(\"слово1\", \"?\"))\n",
    "print(f\"слово1 <> слово2 =\", same(\"слово1\", \"слово2\"))\n",
    "print(f\"!      <> слово2 =\", same(\"!\",      \"слово2\"))\n",
    "print(f\"!      <> ?      =\", same(\"!\",      \"?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1eaeee96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def creade_distance_matrix_with_punctuation(reference_text: str, recognized_text: str) -> list[list[int]]:\n",
    "    \"\"\"Построение матрицы расстояний с учетом пунктуации.\"\"\"\n",
    "\n",
    "    # Приведение текста к нижнему регистру, удаление символов пунктуации и разбивка на слова\n",
    "    reference_words = preprocess_text_with_punctuation(reference_text)\n",
    "    recognized_words = preprocess_text_with_punctuation(recognized_text)\n",
    "\n",
    "    # Инициализация матрицы для подсчета расстояния между словами\n",
    "    distance_matrix = [[0] * (len(recognized_words) + 1) for _ in range(len(reference_words) + 1)]\n",
    "    \n",
    "    # Наполнение первой строки матрицы\n",
    "    for i in range(len(reference_words) + 1):\n",
    "        distance_matrix[i][0] = i\n",
    "\n",
    "    # Наполнение первого столбца матрицы\n",
    "    for j in range(len(recognized_words) + 1):\n",
    "        distance_matrix[0][j] = j\n",
    "\n",
    "    def cost(i:int, j:int) -> int:\n",
    "        return 0 if reference_words[i-1] == recognized_words[j-1] else 1\n",
    "\n",
    "    # Заполнение матрицы расстояний методом динамического программирования\n",
    "    for i in range(1, len(reference_words) + 1):\n",
    "        for j in range(1, len(recognized_words) + 1):\n",
    "            operations = [\n",
    "                distance_matrix[i][j-1] + 1,\n",
    "                distance_matrix[i-1][j] + 1,\n",
    "            ]\n",
    "\n",
    "            if same(reference_words[i-1], recognized_words[j-1]):\n",
    "                operations.append(distance_matrix[i-1][j-1] + cost(i, j))\n",
    "\n",
    "            distance_matrix[i][j] = min(operations)\n",
    "\n",
    "    return distance_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f331de14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "wer = 87.5\n",
      "per = 100.0\n",
      "\n",
      "Результат:\n",
      "\n",
      "***  Я  ***  ***      ***      сегодня  учусь  в  университете  ИТМО   .    A   ты    ?\n",
      " А   я   ?    С   завтрашнего    дня    учусь  в      ***       ИТМО   .   ***  ***  ***\n",
      " I   C  I_p   I        I          S       C    C       D         C    C_p   D    D   D_p\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def calculate_wer_per(reference_text: str, recognized_text: str):\n",
    "\n",
    "    # разбивка текста на слова и удаление пунктуации\n",
    "    reference_words = preprocess_text(reference_text, original_case=True)\n",
    "\n",
    "    # разбивка текста с пунктуацией\n",
    "    reference_words_punkt = preprocess_text_with_punctuation(reference_text, original_case=True)\n",
    "    recognized_words_punkt = preprocess_text_with_punctuation(recognized_text, original_case=True)\n",
    "\n",
    "    # используя distance_matrix восстановите путь (набор операций), который соответстует найденому WER \n",
    "    insertion = 0     # horisontal move\n",
    "    deletion = 0      # vertical move\n",
    "    substitution = 0  # diagonal move\n",
    "    correct = 0\n",
    "    ali = [\n",
    "        [], # reference\n",
    "        [], # recognized\n",
    "        [], # operations\n",
    "    ]\n",
    "\n",
    "    # матрица расстояний для текста со знаками препинания\n",
    "    distance_matrix = creade_distance_matrix_with_punctuation(reference_text, recognized_text)\n",
    "\n",
    "    # количество вставок, удалений и замен для знаков препинания\n",
    "    levenstein_distance = 0\n",
    "    levenstein_distance_per = 0\n",
    "\n",
    "    i = len(distance_matrix) - 1\n",
    "    j = len(distance_matrix[0]) - 1\n",
    "    finished = False\n",
    "    while i > 0 or j > 0:\n",
    "        current_value = distance_matrix[i][j]\n",
    "\n",
    "        try_insertion = distance_matrix[i][j-1]\n",
    "        try_deletion = distance_matrix[i-1][j]\n",
    "        try_substitution = distance_matrix[i-1][j-1]\n",
    "\n",
    "        min_value = min([try_insertion, try_deletion, try_substitution])\n",
    "\n",
    "        # ход по диагонали\n",
    "        if try_substitution == min_value and abs(current_value - min_value) <= 1:\n",
    "            if current_value - min_value == 1:\n",
    "                substitution += 1\n",
    "                ali[2].append(\"S\")\n",
    "            else:\n",
    "                correct += 1\n",
    "                ali[2].append(\"C\")\n",
    "\n",
    "            i -= 1\n",
    "            j -= 1\n",
    "\n",
    "            ali[0].append(reference_words_punkt[i])\n",
    "            ali[1].append(recognized_words_punkt[j])\n",
    "\n",
    "            if not is_word(reference_words_punkt[i]):\n",
    "                ali[2][-1] += \"_p\"\n",
    "                if ali[2][-1] != \"C_p\":\n",
    "                    levenstein_distance_per += 1\n",
    "            else:\n",
    "                if ali[2][-1] != \"C\":\n",
    "                    levenstein_distance += 1\n",
    "\n",
    "        # ход по вертикали\n",
    "        elif try_deletion == min_value and abs(current_value - min_value) <= 1:\n",
    "            deletion += 1\n",
    "            i -= 1\n",
    "\n",
    "            ali[2].append(\"D\")\n",
    "            ali[0].append(reference_words_punkt[i])\n",
    "            ali[1].append(\"***\")\n",
    "\n",
    "            if not is_word(reference_words_punkt[i]):\n",
    "                ali[2][-1] += \"_p\"\n",
    "                levenstein_distance_per += 1\n",
    "            else:\n",
    "                levenstein_distance += 1\n",
    "\n",
    "        # ход по горизонтали\n",
    "        else:\n",
    "            insertion += 1\n",
    "            j -= 1\n",
    "\n",
    "            ali[2].append(\"I\")\n",
    "            ali[0].append(\"***\")\n",
    "            ali[1].append(recognized_words_punkt[j])\n",
    "\n",
    "            if not is_word(recognized_words_punkt[j]):\n",
    "                ali[2][-1] += \"_p\"\n",
    "                levenstein_distance_per += 1\n",
    "            else:\n",
    "                levenstein_distance += 1\n",
    "\n",
    "    # ali[0]=  разбитый по словам референс. Втавки отабражаются в эталонном выравнивании с помощью \"***\"\n",
    "    # ali[1] = разбитая по словам гипотеза.\n",
    "    # ali[2] = аннотация \n",
    "    assert len(ali[0]) == len(ali[1]) == len(ali[2]), f\"wrong ali {ali}\"\n",
    "\n",
    "    wer = levenstein_distance / (len(reference_words)) * 100\n",
    "    per = levenstein_distance_per / (len(reference_words_punkt) - len(reference_words)) * 100\n",
    "\n",
    "    return {\"wer\": wer, # calculate_wer(reference_text, recognized_text),\n",
    "            \"per\": per,\n",
    "            \"ali\": [ list(reversed(line)) for line in ali ]}\n",
    "\n",
    "\n",
    "# отладочный запуск\n",
    "result = calculate_wer_per(\n",
    "    \"Я сегодня учусь в университете ИТМО. A ты?\",\n",
    "    \"А я? С завтрашнего дня учусь в ИТМО.\"\n",
    ")\n",
    "\n",
    "print(f\"\"\"\n",
    "wer = {result[\"wer\"]}\n",
    "per = {result[\"per\"]}\n",
    "\n",
    "Результат:\n",
    "\n",
    "{tabulate(result[\"ali\"], stralign=\"center\", tablefmt=\"plain\")}\n",
    "\"\"\")\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "31f053d5-2015-4d33-8ded-e5d0160e8901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 2 passed\n"
     ]
    }
   ],
   "source": [
    "def assert_wer_per(ref, hyp, ideal_report):\n",
    "    report = calculate_wer_per(ref, hyp)\n",
    "    for k, v in ideal_report.items():\n",
    "        if isinstance(v, float):\n",
    "            assert round(v, 2) == round(report[k], 2), f\"for '{hyp=}' and '{ref=}' {ideal_report=}, calculate_wer {report=}\"\n",
    "        else:\n",
    "            assert v == report[k], f\"for '{hyp=}' and '{ref=}' {ideal_report=}, calculate_wer {report=}\"\n",
    "\n",
    "    \n",
    "def test_wer_per():\n",
    "    assert_wer_per('привет студент.', 'привет студент',  {\n",
    "            \"wer\" : 0,\n",
    "            \"per\": 100})\n",
    "    assert_wer_per('привет студент.', 'студент.', {\n",
    "            \"wer\" : 50,\n",
    "            \"per\": 0,})\n",
    "    assert_wer_per('привет студент.', 'привет. студент',  {\n",
    "            \"wer\" : 0,\n",
    "            \"per\": 200})\n",
    "    assert_wer_per('привет студент.', '.студент?', {\n",
    "            \"wer\" : 50,\n",
    "            \"per\": 200, })\n",
    "\n",
    "    print(f\"Test 2 passed\")\n",
    "    \n",
    "test_wer_per() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb08f8da-e0f9-48e4-b584-3d1ab25c279c",
   "metadata": {},
   "source": [
    "# 3. Speaker-attributed Word Error Rate (4 балла)\n",
    "\n",
    "В задаче распознавания диалоговых данных, когда говорят два диктора, важно не только распознать правильно каждое слово, но и отнести его к правильному диктору. Чаще всего такой результат получается с помощью комбинации двух независимых систем: распознавания речи и диаризация. \n",
    "\n",
    "При подсчете ошибки распознавания диалоговых систем в формулу WER добавляется еще один тип ошибки - S_I (speaker incorrect).\n",
    "\n",
    "$$ SA{\\text -}WER = \\min{I + D + S + S_I \\over D + S + C + S_I} $$\n",
    "\n",
    "Кроме подсчета самой ошибки, sa-wer решает еще одну задачку - поиск маппинга из эталонных названий спикеров (например, имен) в предсказанные (чаще всего Idшники). Это необходимо, тк система диаризации не знает, какие названия у спикеров в эталоне. При подсчете SA-WER проверяются все возможные мапинги спикеров и выбирается тот, который соответствует минимальному значению ошибки. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "59f99f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_distance_matrix_simplified(reference_words:list[str], recognized_words:list[str]) -> list[list[int]]:\n",
    "    \"\"\"Построение матрицы расстояний по массивам слов.\"\"\"\n",
    "\n",
    "    # Инициализация матрицы для подсчета расстояния между словами\n",
    "    distance_matrix = [[0] * (len(recognized_words) + 1) for _ in range(len(reference_words) + 1)]\n",
    "    \n",
    "    # Наполнение первой строки матрицы\n",
    "    for i in range(len(reference_words) + 1):\n",
    "        distance_matrix[i][0] = i\n",
    "\n",
    "    # Наполнение первого столбца матрицы\n",
    "    for j in range(len(recognized_words) + 1):\n",
    "        distance_matrix[0][j] = j\n",
    "\n",
    "    def cost(i:int, j:int) -> int:\n",
    "        return 0 if reference_words[i-1] == recognized_words[j-1] else 1\n",
    "\n",
    "    # Заполнение матрицы расстояний методом динамического программирования\n",
    "    for i in range(1, len(reference_words) + 1):\n",
    "        for j in range(1, len(recognized_words) + 1):\n",
    "            distance_matrix[i][j] = min([\n",
    "                distance_matrix[i][j-1] + 1,\n",
    "                distance_matrix[i-1][j] + 1,\n",
    "                distance_matrix[i-1][j-1] + cost(i, j),\n",
    "            ])\n",
    "\n",
    "    return distance_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "acb29784-c8cc-44bb-a8c4-118c5c0da9d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sawer': 25.0, 'ali': {'А': 1, 'B': 2, 'С': None}}\n"
     ]
    }
   ],
   "source": [
    "def calculate_sawer(reference_text:list[str], reference_speakers:list[str], recognized_text:list[int], recognized_speakers:list[str]):\n",
    "\n",
    "    # В отличие от прошлых функций на вход sawer подаются уже разбитые на слова произнесения\n",
    "    # Кроме списка слов, дополнительно передается список меток спикеров\n",
    "    assert isinstance(reference_text, list)\n",
    "    assert isinstance(recognized_text, list)\n",
    "    assert len(reference_text) == len(reference_speakers)\n",
    "    assert len(recognized_text) == len(recognized_speakers)\n",
    "    \n",
    "    # TODO  посчитайте sawer с учетом мапинга спикеров\n",
    "    # для этого посчитайте значение ошибки для каждого варианта мапинга меток дикторов \n",
    "    # и выберете тот, который соответствует минимальному SA-WER\n",
    "\n",
    "    # расстояние Левенштейна\n",
    "    distance_matrix = create_distance_matrix_simplified(reference_text, recognized_text)\n",
    "    levenstein_distance = distance_matrix[-1][-1]\n",
    "\n",
    "    # используя distance_matrix составляем список правильно распознанных слов \n",
    "    # и соответствующих им эталонных и распознанных дикторов\n",
    "    speakers_sequence = []\n",
    "\n",
    "    i = len(distance_matrix) - 1\n",
    "    j = len(distance_matrix[0]) - 1\n",
    "    finished = False\n",
    "    while i > 0 or j > 0:\n",
    "        current_value = distance_matrix[i][j]\n",
    "\n",
    "        try_insertion = distance_matrix[i][j-1]\n",
    "        try_deletion = distance_matrix[i-1][j]\n",
    "        try_substitution = distance_matrix[i-1][j-1]\n",
    "\n",
    "        min_value = min([try_insertion, try_deletion, try_substitution])\n",
    "\n",
    "        # ход по диагонали\n",
    "        if try_substitution == min_value and abs(current_value - min_value) <= 1:\n",
    "\n",
    "            # корректно распознанное слово\n",
    "            if current_value - min_value != 1:\n",
    "                speakers_sequence.append({\n",
    "                    \"reference_name\": reference_speakers[i-1],\n",
    "                    \"recognized_id\": recognized_speakers[j-1],\n",
    "                })\n",
    "\n",
    "            i -= 1\n",
    "            j -= 1\n",
    "\n",
    "        elif try_insertion == min_value and abs(current_value - min_value) <= 1:\n",
    "            j -= 1\n",
    "\n",
    "        else:\n",
    "            i -= 1\n",
    "\n",
    "    # т.к. шли с конца, возвращаем верный порядок\n",
    "    speakers_sequence.reverse()\n",
    "\n",
    "    #\n",
    "    # теперь необходимо найти все возможные варианты мапингов `{\"reference_name\": reference_id}`\n",
    "    #\n",
    "\n",
    "    # выбираем унивальные имена дикторов, слова которых распознаны,\n",
    "    # т.к. только они участвуют в расчетах\n",
    "    reference_names = list({ speaker[\"reference_name\"] for speaker in speakers_sequence })\n",
    "\n",
    "    # выбираем уникальные идентификаторы дикторов для слов, которые были распознаны\n",
    "    recognized_ids = list({ speaker[\"recognized_id\"] for speaker in speakers_sequence })\n",
    "    if len(recognized_ids) < len(reference_names):\n",
    "        recognized_ids.extend([None]*(len(reference_names) - len(recognized_ids)))\n",
    "\n",
    "    # собираем все возможные варианты соответствия\n",
    "    ids_permutations = list(itertools.permutations(recognized_ids))\n",
    "\n",
    "    # считаем количество ошибочных распознаваний для каждой комбинации\n",
    "    # и попутно ищем минимальное\n",
    "    min_detection_errors = None\n",
    "    best_mapping = None\n",
    "    for reference_ids in ids_permutations:\n",
    "        mapping = { combination[0]: combination[1] for combination in zip(reference_names, reference_ids) }\n",
    "\n",
    "        detection_errors = 0\n",
    "        for speaker in speakers_sequence:\n",
    "            reference_id = mapping[speaker[\"reference_name\"]]\n",
    "            if reference_id != speaker[\"recognized_id\"]:\n",
    "                detection_errors += 1\n",
    "        \n",
    "        if min_detection_errors is None or detection_errors < min_detection_errors:\n",
    "            best_mapping = mapping\n",
    "            min_detection_errors = detection_errors\n",
    "\n",
    "    sawer = (levenstein_distance + min_detection_errors) / len(reference_text) * 100\n",
    "\n",
    "    ali = best_mapping\n",
    "    return {\"sawer\" : sawer, \n",
    "            \"ali\": ali}\n",
    "\n",
    "sawer = calculate_sawer(\n",
    "    reference_text=['привет', 'студент', \"как\", \"дела\"],\n",
    "    recognized_text=['привет', 'студент', \"как\", \"дела\"],\n",
    "    reference_speakers=['А', 'B', \"С\", \"А\"],\n",
    "    recognized_speakers=[1, 2, 1, 1],\n",
    ")\n",
    "\n",
    "print(sawer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1c70f023-8c9f-4aeb-b4ee-fd41f2191c26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 3 passed\n"
     ]
    }
   ],
   "source": [
    "def assert_sawer(reference_text, reference_speakers, recognized_text, recognized_speakers, ideal_report):\n",
    "    report = calculate_sawer(reference_text, reference_speakers, recognized_text, recognized_speakers)\n",
    "    for k, v in ideal_report.items():\n",
    "        assert v == report[k]\n",
    "\n",
    "    \n",
    "def test_sawer():\n",
    "    assert_sawer(['привет', 'студент'], ['A', 'B'], ['привет', 'студент'], [1, 2],  {\n",
    "            \"sawer\" : 0})\n",
    "    assert_sawer(['привет', 'студент'], ['A', 'A'], ['привет', 'студент'], [1, 2],  {\n",
    "            \"sawer\" : 50})\n",
    "    assert_sawer(['привет', 'студент'], ['A', 'A'], ['привет', 'студент'], [0, 0],  {\n",
    "            \"sawer\" : 0})\n",
    "    assert_sawer(['привет', 'с'], ['A', 'B'], ['привет', 'студент'], [1, 2],  {\n",
    "            \"sawer\" : 50})\n",
    "    assert_sawer(['привет', 'с'], ['A', 'B'], ['привет'], [1],  {\n",
    "            \"sawer\" : 50})\n",
    "    assert_sawer(['привет'], ['A'], ['привет', 'студент'], [1, 0],  {\n",
    "            \"sawer\" : 100})\n",
    "    assert_sawer(['привет'], ['A'], ['привет', 'студент'], [0, 0],  {\n",
    "            \"sawer\" : 100})\n",
    "\n",
    "    print(f\"Test 3 passed\")\n",
    "    \n",
    "test_sawer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f758f45-926e-4d8b-a25f-c28578c6de0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
